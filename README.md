# CV_Project
Eye Gaze Dataset Creation and Classification
This code creates a labelled dataset for gaze classification using eye-tracking image data. It processes data from multiple subjects, stored in CSV and image formats, and organizes the data into training, validation, and test sets based on specified proportions. The script loads subject-specific metadata CSV files containing gaze information and associated image filenames, filters out ignored subjects, and splits the data by subject to prevent bias. It then copies the corresponding image files into output directories categorized by gaze style and split (train/valid/test), renaming them for consistency.
A convolutional neural network (CNN) using PyTorch classifies gaze style from image data. It loads and preprocesses labelled images by resizing them and normalizing pixel values. The dataset is divided into training and validation sets using ImageFolder and DataLoader. A custom CNN architecture is defined with multiple convolutional, ReLU, and dropout layers followed by a fully connected output layer for classification. The model is trained using the Adam optimizer and cross-entropy loss, with accuracy tracked at each epoch. The best-performing model based on validation accuracy is saved for later use.
